{"ast":null,"code":"'use strict';\n\nconst {\n  Transform\n} = require('stream');\nconst Tokenizer = require('parse5/lib/tokenizer');\nconst LocationInfoTokenizerMixin = require('parse5/lib/extensions/location-info/tokenizer-mixin');\nconst Mixin = require('parse5/lib/utils/mixin');\nconst mergeOptions = require('parse5/lib/utils/merge-options');\nconst DevNullStream = require('./dev-null-stream');\nconst ParserFeedbackSimulator = require('./parser-feedback-simulator');\nconst DEFAULT_OPTIONS = {\n  sourceCodeLocationInfo: false\n};\nclass SAXParser extends Transform {\n  constructor(options) {\n    super({\n      encoding: 'utf8',\n      decodeStrings: false\n    });\n    this.options = mergeOptions(DEFAULT_OPTIONS, options);\n    this.tokenizer = new Tokenizer(options);\n    this.locInfoMixin = null;\n    if (this.options.sourceCodeLocationInfo) {\n      this.locInfoMixin = Mixin.install(this.tokenizer, LocationInfoTokenizerMixin);\n    }\n    this.parserFeedbackSimulator = new ParserFeedbackSimulator(this.tokenizer);\n    this.pendingText = null;\n    this.lastChunkWritten = false;\n    this.stopped = false;\n\n    // NOTE: always pipe stream to the /dev/null stream to avoid\n    // `highWaterMark` hit even if we don't have consumers.\n    // (see: https://github.com/inikulin/parse5/issues/97#issuecomment-171940774)\n    this.pipe(new DevNullStream());\n  }\n\n  //TransformStream implementation\n  _transform(chunk, encoding, callback) {\n    if (typeof chunk !== 'string') {\n      throw new TypeError('Parser can work only with string streams.');\n    }\n    callback(null, this._transformChunk(chunk));\n  }\n  _final(callback) {\n    this.lastChunkWritten = true;\n    callback(null, this._transformChunk(''));\n  }\n  stop() {\n    this.stopped = true;\n  }\n\n  //Internals\n  _transformChunk(chunk) {\n    if (!this.stopped) {\n      this.tokenizer.write(chunk, this.lastChunkWritten);\n      this._runParsingLoop();\n    }\n    return chunk;\n  }\n  _runParsingLoop() {\n    let token = null;\n    do {\n      token = this.parserFeedbackSimulator.getNextToken();\n      if (token.type === Tokenizer.HIBERNATION_TOKEN) {\n        break;\n      }\n      if (token.type === Tokenizer.CHARACTER_TOKEN || token.type === Tokenizer.WHITESPACE_CHARACTER_TOKEN || token.type === Tokenizer.NULL_CHARACTER_TOKEN) {\n        if (this.pendingText === null) {\n          token.type = Tokenizer.CHARACTER_TOKEN;\n          this.pendingText = token;\n        } else {\n          this.pendingText.chars += token.chars;\n          if (this.options.sourceCodeLocationInfo) {\n            const {\n              endLine,\n              endCol,\n              endOffset\n            } = token.location;\n            Object.assign(this.pendingText.location, {\n              endLine,\n              endCol,\n              endOffset\n            });\n          }\n        }\n      } else {\n        this._emitPendingText();\n        this._handleToken(token);\n      }\n    } while (!this.stopped && token.type !== Tokenizer.EOF_TOKEN);\n  }\n  _handleToken(token) {\n    if (token.type === Tokenizer.EOF_TOKEN) {\n      return true;\n    }\n    const {\n      eventName,\n      reshapeToken\n    } = TOKEN_EMISSION_HELPERS[token.type];\n    if (this.listenerCount(eventName) === 0) {\n      return false;\n    }\n    this._emitToken(eventName, reshapeToken(token));\n    return true;\n  }\n  _emitToken(eventName, token) {\n    this.emit(eventName, token);\n  }\n  _emitPendingText() {\n    if (this.pendingText !== null) {\n      this._handleToken(this.pendingText);\n      this.pendingText = null;\n    }\n  }\n}\nconst TOKEN_EMISSION_HELPERS = {\n  [Tokenizer.START_TAG_TOKEN]: {\n    eventName: 'startTag',\n    reshapeToken: origToken => ({\n      tagName: origToken.tagName,\n      attrs: origToken.attrs,\n      selfClosing: origToken.selfClosing,\n      sourceCodeLocation: origToken.location\n    })\n  },\n  [Tokenizer.END_TAG_TOKEN]: {\n    eventName: 'endTag',\n    reshapeToken: origToken => ({\n      tagName: origToken.tagName,\n      sourceCodeLocation: origToken.location\n    })\n  },\n  [Tokenizer.COMMENT_TOKEN]: {\n    eventName: 'comment',\n    reshapeToken: origToken => ({\n      text: origToken.data,\n      sourceCodeLocation: origToken.location\n    })\n  },\n  [Tokenizer.DOCTYPE_TOKEN]: {\n    eventName: 'doctype',\n    reshapeToken: origToken => ({\n      name: origToken.name,\n      publicId: origToken.publicId,\n      systemId: origToken.systemId,\n      sourceCodeLocation: origToken.location\n    })\n  },\n  [Tokenizer.CHARACTER_TOKEN]: {\n    eventName: 'text',\n    reshapeToken: origToken => ({\n      text: origToken.chars,\n      sourceCodeLocation: origToken.location\n    })\n  }\n};\nmodule.exports = SAXParser;","map":{"version":3,"names":["Transform","require","Tokenizer","LocationInfoTokenizerMixin","Mixin","mergeOptions","DevNullStream","ParserFeedbackSimulator","DEFAULT_OPTIONS","sourceCodeLocationInfo","SAXParser","constructor","options","encoding","decodeStrings","tokenizer","locInfoMixin","install","parserFeedbackSimulator","pendingText","lastChunkWritten","stopped","pipe","_transform","chunk","callback","TypeError","_transformChunk","_final","stop","write","_runParsingLoop","token","getNextToken","type","HIBERNATION_TOKEN","CHARACTER_TOKEN","WHITESPACE_CHARACTER_TOKEN","NULL_CHARACTER_TOKEN","chars","endLine","endCol","endOffset","location","Object","assign","_emitPendingText","_handleToken","EOF_TOKEN","eventName","reshapeToken","TOKEN_EMISSION_HELPERS","listenerCount","_emitToken","emit","START_TAG_TOKEN","origToken","tagName","attrs","selfClosing","sourceCodeLocation","END_TAG_TOKEN","COMMENT_TOKEN","text","data","DOCTYPE_TOKEN","name","publicId","systemId","module","exports"],"sources":["C:/Users/Nawaz/Downloads/mean-stack-authentication-authorization-master/mean-stack-authentication-authorization-master/Frontend/node_modules/parse5-sax-parser/lib/index.js"],"sourcesContent":["'use strict';\n\nconst { Transform } = require('stream');\nconst Tokenizer = require('parse5/lib/tokenizer');\nconst LocationInfoTokenizerMixin = require('parse5/lib/extensions/location-info/tokenizer-mixin');\nconst Mixin = require('parse5/lib/utils/mixin');\nconst mergeOptions = require('parse5/lib/utils/merge-options');\nconst DevNullStream = require('./dev-null-stream');\nconst ParserFeedbackSimulator = require('./parser-feedback-simulator');\n\nconst DEFAULT_OPTIONS = {\n    sourceCodeLocationInfo: false\n};\n\nclass SAXParser extends Transform {\n    constructor(options) {\n        super({ encoding: 'utf8', decodeStrings: false });\n\n        this.options = mergeOptions(DEFAULT_OPTIONS, options);\n\n        this.tokenizer = new Tokenizer(options);\n        this.locInfoMixin = null;\n\n        if (this.options.sourceCodeLocationInfo) {\n            this.locInfoMixin = Mixin.install(this.tokenizer, LocationInfoTokenizerMixin);\n        }\n\n        this.parserFeedbackSimulator = new ParserFeedbackSimulator(this.tokenizer);\n\n        this.pendingText = null;\n\n        this.lastChunkWritten = false;\n        this.stopped = false;\n\n        // NOTE: always pipe stream to the /dev/null stream to avoid\n        // `highWaterMark` hit even if we don't have consumers.\n        // (see: https://github.com/inikulin/parse5/issues/97#issuecomment-171940774)\n        this.pipe(new DevNullStream());\n    }\n\n    //TransformStream implementation\n    _transform(chunk, encoding, callback) {\n        if (typeof chunk !== 'string') {\n            throw new TypeError('Parser can work only with string streams.');\n        }\n\n        callback(null, this._transformChunk(chunk));\n    }\n\n    _final(callback) {\n        this.lastChunkWritten = true;\n        callback(null, this._transformChunk(''));\n    }\n\n    stop() {\n        this.stopped = true;\n    }\n\n    //Internals\n    _transformChunk(chunk) {\n        if (!this.stopped) {\n            this.tokenizer.write(chunk, this.lastChunkWritten);\n            this._runParsingLoop();\n        }\n        return chunk;\n    }\n\n    _runParsingLoop() {\n        let token = null;\n\n        do {\n            token = this.parserFeedbackSimulator.getNextToken();\n\n            if (token.type === Tokenizer.HIBERNATION_TOKEN) {\n                break;\n            }\n\n            if (\n                token.type === Tokenizer.CHARACTER_TOKEN ||\n                token.type === Tokenizer.WHITESPACE_CHARACTER_TOKEN ||\n                token.type === Tokenizer.NULL_CHARACTER_TOKEN\n            ) {\n                if (this.pendingText === null) {\n                    token.type = Tokenizer.CHARACTER_TOKEN;\n                    this.pendingText = token;\n                } else {\n                    this.pendingText.chars += token.chars;\n\n                    if (this.options.sourceCodeLocationInfo) {\n                        const { endLine, endCol, endOffset } = token.location;\n                        Object.assign(this.pendingText.location, {\n                            endLine,\n                            endCol,\n                            endOffset\n                        });\n                    }\n                }\n            } else {\n                this._emitPendingText();\n                this._handleToken(token);\n            }\n        } while (!this.stopped && token.type !== Tokenizer.EOF_TOKEN);\n    }\n\n    _handleToken(token) {\n        if (token.type === Tokenizer.EOF_TOKEN) {\n            return true;\n        }\n\n        const { eventName, reshapeToken } = TOKEN_EMISSION_HELPERS[token.type];\n\n        if (this.listenerCount(eventName) === 0) {\n            return false;\n        }\n\n        this._emitToken(eventName, reshapeToken(token));\n\n        return true;\n    }\n\n    _emitToken(eventName, token) {\n        this.emit(eventName, token);\n    }\n\n    _emitPendingText() {\n        if (this.pendingText !== null) {\n            this._handleToken(this.pendingText);\n            this.pendingText = null;\n        }\n    }\n}\n\nconst TOKEN_EMISSION_HELPERS = {\n    [Tokenizer.START_TAG_TOKEN]: {\n        eventName: 'startTag',\n        reshapeToken: origToken => ({\n            tagName: origToken.tagName,\n            attrs: origToken.attrs,\n            selfClosing: origToken.selfClosing,\n            sourceCodeLocation: origToken.location\n        })\n    },\n    [Tokenizer.END_TAG_TOKEN]: {\n        eventName: 'endTag',\n        reshapeToken: origToken => ({ tagName: origToken.tagName, sourceCodeLocation: origToken.location })\n    },\n    [Tokenizer.COMMENT_TOKEN]: {\n        eventName: 'comment',\n        reshapeToken: origToken => ({ text: origToken.data, sourceCodeLocation: origToken.location })\n    },\n    [Tokenizer.DOCTYPE_TOKEN]: {\n        eventName: 'doctype',\n        reshapeToken: origToken => ({\n            name: origToken.name,\n            publicId: origToken.publicId,\n            systemId: origToken.systemId,\n            sourceCodeLocation: origToken.location\n        })\n    },\n    [Tokenizer.CHARACTER_TOKEN]: {\n        eventName: 'text',\n        reshapeToken: origToken => ({ text: origToken.chars, sourceCodeLocation: origToken.location })\n    }\n};\n\nmodule.exports = SAXParser;\n"],"mappings":"AAAA,YAAY;;AAEZ,MAAM;EAAEA;AAAU,CAAC,GAAGC,OAAO,CAAC,QAAQ,CAAC;AACvC,MAAMC,SAAS,GAAGD,OAAO,CAAC,sBAAsB,CAAC;AACjD,MAAME,0BAA0B,GAAGF,OAAO,CAAC,qDAAqD,CAAC;AACjG,MAAMG,KAAK,GAAGH,OAAO,CAAC,wBAAwB,CAAC;AAC/C,MAAMI,YAAY,GAAGJ,OAAO,CAAC,gCAAgC,CAAC;AAC9D,MAAMK,aAAa,GAAGL,OAAO,CAAC,mBAAmB,CAAC;AAClD,MAAMM,uBAAuB,GAAGN,OAAO,CAAC,6BAA6B,CAAC;AAEtE,MAAMO,eAAe,GAAG;EACpBC,sBAAsB,EAAE;AAC5B,CAAC;AAED,MAAMC,SAAS,SAASV,SAAS,CAAC;EAC9BW,WAAW,CAACC,OAAO,EAAE;IACjB,KAAK,CAAC;MAAEC,QAAQ,EAAE,MAAM;MAAEC,aAAa,EAAE;IAAM,CAAC,CAAC;IAEjD,IAAI,CAACF,OAAO,GAAGP,YAAY,CAACG,eAAe,EAAEI,OAAO,CAAC;IAErD,IAAI,CAACG,SAAS,GAAG,IAAIb,SAAS,CAACU,OAAO,CAAC;IACvC,IAAI,CAACI,YAAY,GAAG,IAAI;IAExB,IAAI,IAAI,CAACJ,OAAO,CAACH,sBAAsB,EAAE;MACrC,IAAI,CAACO,YAAY,GAAGZ,KAAK,CAACa,OAAO,CAAC,IAAI,CAACF,SAAS,EAAEZ,0BAA0B,CAAC;IACjF;IAEA,IAAI,CAACe,uBAAuB,GAAG,IAAIX,uBAAuB,CAAC,IAAI,CAACQ,SAAS,CAAC;IAE1E,IAAI,CAACI,WAAW,GAAG,IAAI;IAEvB,IAAI,CAACC,gBAAgB,GAAG,KAAK;IAC7B,IAAI,CAACC,OAAO,GAAG,KAAK;;IAEpB;IACA;IACA;IACA,IAAI,CAACC,IAAI,CAAC,IAAIhB,aAAa,EAAE,CAAC;EAClC;;EAEA;EACAiB,UAAU,CAACC,KAAK,EAAEX,QAAQ,EAAEY,QAAQ,EAAE;IAClC,IAAI,OAAOD,KAAK,KAAK,QAAQ,EAAE;MAC3B,MAAM,IAAIE,SAAS,CAAC,2CAA2C,CAAC;IACpE;IAEAD,QAAQ,CAAC,IAAI,EAAE,IAAI,CAACE,eAAe,CAACH,KAAK,CAAC,CAAC;EAC/C;EAEAI,MAAM,CAACH,QAAQ,EAAE;IACb,IAAI,CAACL,gBAAgB,GAAG,IAAI;IAC5BK,QAAQ,CAAC,IAAI,EAAE,IAAI,CAACE,eAAe,CAAC,EAAE,CAAC,CAAC;EAC5C;EAEAE,IAAI,GAAG;IACH,IAAI,CAACR,OAAO,GAAG,IAAI;EACvB;;EAEA;EACAM,eAAe,CAACH,KAAK,EAAE;IACnB,IAAI,CAAC,IAAI,CAACH,OAAO,EAAE;MACf,IAAI,CAACN,SAAS,CAACe,KAAK,CAACN,KAAK,EAAE,IAAI,CAACJ,gBAAgB,CAAC;MAClD,IAAI,CAACW,eAAe,EAAE;IAC1B;IACA,OAAOP,KAAK;EAChB;EAEAO,eAAe,GAAG;IACd,IAAIC,KAAK,GAAG,IAAI;IAEhB,GAAG;MACCA,KAAK,GAAG,IAAI,CAACd,uBAAuB,CAACe,YAAY,EAAE;MAEnD,IAAID,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACiC,iBAAiB,EAAE;QAC5C;MACJ;MAEA,IACIH,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACkC,eAAe,IACxCJ,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACmC,0BAA0B,IACnDL,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAACoC,oBAAoB,EAC/C;QACE,IAAI,IAAI,CAACnB,WAAW,KAAK,IAAI,EAAE;UAC3Ba,KAAK,CAACE,IAAI,GAAGhC,SAAS,CAACkC,eAAe;UACtC,IAAI,CAACjB,WAAW,GAAGa,KAAK;QAC5B,CAAC,MAAM;UACH,IAAI,CAACb,WAAW,CAACoB,KAAK,IAAIP,KAAK,CAACO,KAAK;UAErC,IAAI,IAAI,CAAC3B,OAAO,CAACH,sBAAsB,EAAE;YACrC,MAAM;cAAE+B,OAAO;cAAEC,MAAM;cAAEC;YAAU,CAAC,GAAGV,KAAK,CAACW,QAAQ;YACrDC,MAAM,CAACC,MAAM,CAAC,IAAI,CAAC1B,WAAW,CAACwB,QAAQ,EAAE;cACrCH,OAAO;cACPC,MAAM;cACNC;YACJ,CAAC,CAAC;UACN;QACJ;MACJ,CAAC,MAAM;QACH,IAAI,CAACI,gBAAgB,EAAE;QACvB,IAAI,CAACC,YAAY,CAACf,KAAK,CAAC;MAC5B;IACJ,CAAC,QAAQ,CAAC,IAAI,CAACX,OAAO,IAAIW,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAAC8C,SAAS;EAChE;EAEAD,YAAY,CAACf,KAAK,EAAE;IAChB,IAAIA,KAAK,CAACE,IAAI,KAAKhC,SAAS,CAAC8C,SAAS,EAAE;MACpC,OAAO,IAAI;IACf;IAEA,MAAM;MAAEC,SAAS;MAAEC;IAAa,CAAC,GAAGC,sBAAsB,CAACnB,KAAK,CAACE,IAAI,CAAC;IAEtE,IAAI,IAAI,CAACkB,aAAa,CAACH,SAAS,CAAC,KAAK,CAAC,EAAE;MACrC,OAAO,KAAK;IAChB;IAEA,IAAI,CAACI,UAAU,CAACJ,SAAS,EAAEC,YAAY,CAAClB,KAAK,CAAC,CAAC;IAE/C,OAAO,IAAI;EACf;EAEAqB,UAAU,CAACJ,SAAS,EAAEjB,KAAK,EAAE;IACzB,IAAI,CAACsB,IAAI,CAACL,SAAS,EAAEjB,KAAK,CAAC;EAC/B;EAEAc,gBAAgB,GAAG;IACf,IAAI,IAAI,CAAC3B,WAAW,KAAK,IAAI,EAAE;MAC3B,IAAI,CAAC4B,YAAY,CAAC,IAAI,CAAC5B,WAAW,CAAC;MACnC,IAAI,CAACA,WAAW,GAAG,IAAI;IAC3B;EACJ;AACJ;AAEA,MAAMgC,sBAAsB,GAAG;EAC3B,CAACjD,SAAS,CAACqD,eAAe,GAAG;IACzBN,SAAS,EAAE,UAAU;IACrBC,YAAY,EAAEM,SAAS,KAAK;MACxBC,OAAO,EAAED,SAAS,CAACC,OAAO;MAC1BC,KAAK,EAAEF,SAAS,CAACE,KAAK;MACtBC,WAAW,EAAEH,SAAS,CAACG,WAAW;MAClCC,kBAAkB,EAAEJ,SAAS,CAACb;IAClC,CAAC;EACL,CAAC;EACD,CAACzC,SAAS,CAAC2D,aAAa,GAAG;IACvBZ,SAAS,EAAE,QAAQ;IACnBC,YAAY,EAAEM,SAAS,KAAK;MAAEC,OAAO,EAAED,SAAS,CAACC,OAAO;MAAEG,kBAAkB,EAAEJ,SAAS,CAACb;IAAS,CAAC;EACtG,CAAC;EACD,CAACzC,SAAS,CAAC4D,aAAa,GAAG;IACvBb,SAAS,EAAE,SAAS;IACpBC,YAAY,EAAEM,SAAS,KAAK;MAAEO,IAAI,EAAEP,SAAS,CAACQ,IAAI;MAAEJ,kBAAkB,EAAEJ,SAAS,CAACb;IAAS,CAAC;EAChG,CAAC;EACD,CAACzC,SAAS,CAAC+D,aAAa,GAAG;IACvBhB,SAAS,EAAE,SAAS;IACpBC,YAAY,EAAEM,SAAS,KAAK;MACxBU,IAAI,EAAEV,SAAS,CAACU,IAAI;MACpBC,QAAQ,EAAEX,SAAS,CAACW,QAAQ;MAC5BC,QAAQ,EAAEZ,SAAS,CAACY,QAAQ;MAC5BR,kBAAkB,EAAEJ,SAAS,CAACb;IAClC,CAAC;EACL,CAAC;EACD,CAACzC,SAAS,CAACkC,eAAe,GAAG;IACzBa,SAAS,EAAE,MAAM;IACjBC,YAAY,EAAEM,SAAS,KAAK;MAAEO,IAAI,EAAEP,SAAS,CAACjB,KAAK;MAAEqB,kBAAkB,EAAEJ,SAAS,CAACb;IAAS,CAAC;EACjG;AACJ,CAAC;AAED0B,MAAM,CAACC,OAAO,GAAG5D,SAAS"},"metadata":{},"sourceType":"script","externalDependencies":[]}